#!/usr/bin/env python
import time
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from macad_gym.carla.multi_env import MultiCarlaEnv
import torch

from torch.autograd import Variable
from macad_gym.buffer import ReplayBuffer
from macad_gym.matd3 import MATD3
import numpy as np


class StopSign3CarTown03(MultiCarlaEnv):
    """A 4-way signalized intersection Multi-Agent Carla-Gym environment"""
    def __init__(self):
        self.configs = {
            "scenarios": "Custom_yoon",
            "env": {
                "server_map": "/Game/Carla/Maps/Town05",
                "render": True,
                "render_x_res": 800,
                "render_y_res": 600,
                "x_res": 168,
                "y_res": 168,
                "framestack": 1,
                "discrete_actions": False,
                "squash_action_logits": False,
                "verbose": False,                     
                "use_depth_camera": False,
                "send_measurements": False,
                "enable_planner": True,
                "spectator_loc": [-44.42, 0, 40],        
                "sync_server": True,
                "fixed_delta_seconds": 0.05,
            },
            "actors": {    
                "car1": {
                    "type": "vehicle_4W",
                    "enable_planner": True,
                    "convert_images_to_video": False,
                    "early_terminate_on_collision": True,
                    "reward_function": "corl2017",
                    "scenarios": "SSUI3C_TOWN3_CAR1",
                    "manual_control":  False,
                    "auto_control": False,
                    "camera_type": "rgb",
                    "collision_sensor": "on",
                    "lane_sensor": "on",
                    "log_images": False,
                    "log_measurements": False,
                    "render": True,
                    "x_res": 168,
                    "y_res": 168,
                    "use_depth_camera": False,
                    "send_measurements": False,
                },
                "car2": {
                    "type": "vehicle_4W",
                    "enable_planner": True,
                    "convert_images_to_video": False,
                    "early_terminate_on_collision": True,
                    "reward_function": "corl2017",
                    "scenarios": "SSUI3C_TOWN3_CAR2",
                    "manual_control": False,
                    "auto_control": False,
                    "camera_type": "rgb",
                    "collision_sensor": "on",
                    "lane_sensor": "on",
                    "log_images": False,
                    "log_measurements": False,
                    "render": True,
                    "x_res": 168,
                    "y_res": 168,
                    "use_depth_camera": False,
                    "send_measurements": False,
                },
                "car3": {
                    "type": "vehicle_4W",
                    "enable_planner": True,
                    "convert_images_to_video": False,
                    "early_terminate_on_collision": True,
                    "reward_function": "corl2017",
                    "scenarios": "SSUI3C_TOWN3_CAR3",
                    "manual_control": False,
                    "auto_control": False,
                    "camera_type": "rgb",
                    "collision_sensor": "on",
                    "lane_sensor": "on",
                    "log_images": False,
                    "log_measurements": False,
                    "render": True,
                    "x_res": 168,
                    "y_res": 168,
                    "use_depth_camera": False,
                    "send_measurements": False,
                },
                "car4": {
                    "type": "vehicle_4W",
                    "enable_planner": True,
                    "convert_images_to_video": False,
                    "early_terminate_on_collision": True,
                    "reward_function": "corl2017",
                    "scenarios": "SSUI3C_TOWN3_CAR3",
                    "manual_control": False,
                    "auto_control": False,
                    "camera_type": "rgb",
                    "collision_sensor": "on",
                    "lane_sensor": "on",
                    "log_images": False,
                    "log_measurements": False,
                    "render": True,
                    "x_res": 168,
                    "y_res": 168,
                    "use_depth_camera": False,
                    "send_measurements": False,
                }
            },
        }

        super(StopSign3CarTown03, self).__init__(self.configs)

##############################################################################
############################## hong ##########################################
def States_from_info(info): # info = dictionary of py_measurements. 
    S1 = [
        info['car1']['x']-info['car1']['end_pos'][0],
        info['car1']['y']-info['car1']['end_pos'][1],
        info['car1']['x']-info['car2']['x'],
        info['car1']['x']-info['car3']['x'],
        info['car1']['x']-info['car4']['x'],
        info['car1']['y']-info['car2']['y'],
        info['car1']['y']-info['car3']['y'],
        info['car1']['y']-info['car4']['y'],
        info['car1']['v_x']-info['car2']['v_x'],
        info['car1']['v_x']-info['car3']['v_x'],
        info['car1']['v_x']-info['car4']['v_x'],
        info['car1']['v_y']-info['car2']['v_y'],
        info['car1']['v_y']-info['car3']['v_y'],
        info['car1']['v_y']-info['car4']['v_y'],
    ]
    S2 = [
        info['car2']['x']-info['car2']['end_pos'][0],
        info['car2']['y']-info['car2']['end_pos'][1],
        info['car2']['x']-info['car1']['x'],
        info['car2']['x']-info['car3']['x'],
        info['car2']['x']-info['car4']['x'],
        info['car2']['y']-info['car1']['y'],
        info['car2']['y']-info['car3']['y'],
        info['car2']['y']-info['car4']['y'],
        info['car2']['v_x']-info['car1']['v_x'],
        info['car2']['v_x']-info['car3']['v_x'],
        info['car2']['v_x']-info['car4']['v_x'],
        info['car2']['v_y']-info['car1']['v_y'],
        info['car2']['v_y']-info['car3']['v_y'],
        info['car2']['v_y']-info['car4']['v_y'],
    ]
    S3 = [
        info['car3']['x']-info['car3']['end_pos'][0],
        info['car3']['y']-info['car3']['end_pos'][1],
        info['car3']['x']-info['car1']['x'],
        info['car3']['x']-info['car2']['x'],
        info['car3']['x']-info['car4']['x'],
        info['car3']['y']-info['car1']['y'],
        info['car3']['y']-info['car2']['y'],
        info['car3']['y']-info['car4']['y'],
        info['car3']['v_x']-info['car1']['v_x'],
        info['car3']['v_x']-info['car2']['v_x'],
        info['car3']['v_x']-info['car4']['v_x'],
        info['car3']['v_y']-info['car1']['v_y'],
        info['car3']['v_y']-info['car2']['v_y'],
        info['car3']['v_y']-info['car4']['v_y'],
    ]
    S4 = [
        info['car4']['x']-info['car4']['end_pos'][0],
        info['car4']['y']-info['car4']['end_pos'][1],
        info['car4']['x']-info['car1']['x'],
        info['car4']['x']-info['car2']['x'],
        info['car4']['x']-info['car3']['x'],
        info['car4']['y']-info['car1']['y'],
        info['car4']['y']-info['car2']['y'],
        info['car4']['y']-info['car3']['y'],
        info['car4']['v_x']-info['car1']['v_x'],
        info['car4']['v_x']-info['car2']['v_x'],
        info['car4']['v_x']-info['car3']['v_x'],
        info['car4']['v_y']-info['car1']['v_y'],
        info['car4']['v_y']-info['car2']['v_y'],
        info['car4']['v_y']-info['car3']['v_y'],
    ]
    States = np.array([S1, S2, S3, S4]) # [4, 14]
    return States
##############################################################################
##############################################################################


def command_to_steer(command):
    if command == "REACH_GOAL":
        steer = 0
    elif command == "GO_STRAIGHT":
        steer = 0
    elif command == "TURN_RIGHT":
        steer = 0.2
    elif command == "TURN_LEFT":
        steer = -0.2
    elif command == "LANE_FOLLOW":
        steer = 0
    return steer




if __name__ == "__main__":
    env = StopSign3CarTown03()
    configs = env.configs
    env_config = configs["env"]
    actor_configs = configs["actors"]


    np.random.seed(1)

    agent_params = [
        {"num_in_pol": 14, "num_out_pol": 1, "num_in_critic": 60},                          ### before 14
        {"num_in_pol": 14, "num_out_pol": 1, "num_in_critic": 60},
        {"num_in_pol": 14, "num_out_pol": 1, "num_in_critic": 60},
        {"num_in_pol": 14, "num_out_pol": 1, "num_in_critic": 60}
    ]
    obs_dims=[14, 14, 14, 14]
    ac_dims = [1, 1, 1, 1]
    alg_types = ["MATD3", "MATD3", "MATD3", "MATD3"] 
    
    matd3 = MATD3(agent_init_params=agent_params, alg_types=alg_types)

    replay_buffer = ReplayBuffer(int(1e6), matd3.nagents, obs_dims, ac_dims)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    matd3.prep_rollouts(device=device)                                      ### gpu 설정
    
    matd3.to(device)

    batch_size = 256
    steps_per_update = 100

    for ep in range(1000):
        
        total_reward_dict = {}
        action_dict = {}        
        
        obs, info = env.reset()
        States = States_from_info(info)
        
        torch_obs = [Variable(torch.Tensor(np.vstack(States[i, :])).to(device), requires_grad=False) for i in range(States.shape[0])]    
        torch_agent_actions = matd3.step(torch_obs, explore=True)                
        agent_actions = [ac.cpu().data.numpy() for ac in torch_agent_actions] # velocity
        # print(torch_agent_actions)

        car_num = 0
        for actor_id in actor_configs.keys():
            total_reward_dict[actor_id] = 0
            action_dict[actor_id] = [agent_actions[car_num], 0.1]  # velocity, steering
            car_num+=1
        obs, reward, done, info = env.step(action_dict)
        replay_buffer.push_hong(States, agent_actions, reward, States_from_info(info), done) # agents 의 replay_buffer를 모아서 관리
        States = States_from_info(info)        
        # print(action_dict)
        
        if (len(replay_buffer) >= batch_size and (i % steps_per_update) < 1):
            matd3.prep_training(device=device)
            for a_i in range(matd3.nagents): 
                sample = replay_buffer.sample(batch_size, to_gpu=True)
                matd3.update(sample, a_i)
            matd3.update_all_targets()
            matd3.prep_rollouts(device=device)


        torch_obs = [Variable(torch.Tensor(np.vstack(States[i, :])).to(device), requires_grad=False) for i in range(States.shape[0])]
        torch_agent_actions = matd3.step(torch_obs, explore=True)
        agent_actions = [ac.cpu().data.numpy() for ac in torch_agent_actions] # velocity


        start = time.time()
        i = 0
        done = {"__all__": False}
        while not done["__all__"]:            
            i += 1

            car_num = 0
            for actor_id in actor_configs.keys():
                command = info[actor_id]["next_command"]
                steer_value = command_to_steer(command)
                # action_dict[actor_id] = [agent_actions[car_num], steer_value]
                action_dict[actor_id] = [1.0, steer_value]
                car_num+=1
            # print(torch_agent_actions)
            obs, reward, done, info = env.step(action_dict)                      ### info = py_measurements
            replay_buffer.push_hong(States, agent_actions, reward, States_from_info(info), done) # agents 의 replay_buffer를 모아서 관리
            States = States_from_info(info)            
            if (len(replay_buffer) >= batch_size and (i % steps_per_update) < 1):
                matd3.prep_training(device=device)
                for a_i in range(matd3.nagents): 
                    sample = replay_buffer.sample(batch_size, to_gpu=True)
                    matd3.update(sample, a_i)
                matd3.update_all_targets()
                matd3.prep_rollouts(device=device)

            torch_obs = [Variable(torch.Tensor(np.vstack(States[i, :])).to(device), requires_grad=False) for i in range(States.shape[0])]
            torch_agent_actions = matd3.step(torch_obs, explore=True)
            agent_actions = [ac.cpu().data.numpy() for ac in torch_agent_actions] # velocity


            # print(info['car4']["next_command"])
            for actor_id in total_reward_dict.keys():
                total_reward_dict[actor_id] += reward[actor_id]
            # time.sleep(1)

        print("{} fps".format(i / (time.time() - start)))
